model_list:
  - model_name: gpt-4.1-mini
    model_info:
      input_cost_per_token: 0.4e-6
      output_cost_per_token: 1.6e-6
      cache_read_input_token_cost: 0.1e-6
      max_tokens: 2048
    litellm_params:
      model: gpt-4.1-mini
      api_key: os.environ/CHATGPT_API_KEY
      rpm: 5
  
  - model_name: phi-4-14b
    model_info:
      input_cost_per_token: 0.1e-20
      output_cost_per_token: 0.1e-20
      cache_read_input_token_cost: 0.1e-20
      litellm_provider: mlx-community
    litellm_params:
      model: openai/phi-4-abliterated
      api_base: http://host.docker.internal:1234/v1
      api_key: os.environ/LMSTUDIO_API_KEY

  - model_name: gemma-3-4b
    model_info:
      input_cost_per_token: 0.1e-20
      output_cost_per_token: 0.1e-20
      cache_read_input_token_cost: 0.1e-20
      litellm_provider: bartowski
    litellm_params:
      model: openai/mlabonne_gemma-3-4b-it-abliterated
      api_base: http://host.docker.internal:1234/v1
      api_key: os.environ/LMSTUDIO_API_KEY

router_settings:
  provider_budget_config: 
    openai: 
      budget_limit: 0.2
      time_period: 1d
    mlx-community:
      budget_limit: 100
      time_period: 1d
    bartowski:
      budget_limit: 100
      time_period: 1d

general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY

litellm_settings:
  request_timeout: 90
